{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "torch.manual_seed(1746)\n",
                "\n",
                "B,H,T,S,N,P = 8,16,1000,1000,32,32\n",
                "Q = torch.randn(B,T,H,N//H).transpose(1,2)\n",
                "K = torch.randn(B,S,H,N//H).transpose(1,2)\n",
                "V = torch.randn(B,S,H,P//H).transpose(1,2)\n",
                "L = torch.tril(torch.ones(T,S)).view(1,1,T,S)\n",
                "\n",
                "# Standard masked attention\n",
                "G = Q @ K.transpose(-2,-1)\n",
                "M = G * L\n",
                "Y_standard = (M @ V).reshape(B,T,N)\n",
                "\n",
                "# Single contraction\n",
                "Y_contraction = torch.einsum('bhtn,bhsn,bhsp,bhts->bhtp', Q, K, V, L).reshape(B,T,N)\n",
                "print(torch.allclose(Y_standard, Y_contraction, atol=1e-3))\n",
                "\n",
                "# Step-by-step verification\n",
                "G_contraction = torch.einsum('bhtn,bhsn->bhts', Q, K)\n",
                "M_contraction = torch.einsum('bhts,bhts->bhts', G_contraction, L)\n",
                "Y_step_contraction = torch.einsum('bhts,bhsp->bhtp', M_contraction, V).reshape(B,T,N)\n",
                "print(torch.allclose(Y_standard, Y_step_contraction, atol=1e-3))\n",
                "\n",
                "# Derivation for cumsum proof\n",
                "Z = torch.einsum('bhsp,bhsn->bhspn', V, K)\n",
                "H = torch.einsum('bhts,bhspn->bhtpn', L, Z)\n",
                "Y_derivation = torch.einsum('bhtn,bhtpn->bhtp', Q, H).reshape(B,T,N)\n",
                "print(torch.allclose(Y_standard, Y_derivation, atol=1e-3))\n",
                "\n",
                "# Cumulative sum formulation\n",
                "H_cumsum = torch.cumsum(Z, dim=2)\n",
                "Y_cumsum = torch.einsum('bhtn,bhtpn->bhtp', Q, H_cumsum).reshape(B,T,N)\n",
                "print(torch.allclose(Y_standard, Y_cumsum, atol=1e-3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn.functional as F\n",
                "\n",
                "from torch.utils.data import TensorDataset\n",
                "\n",
                "\n",
                "def generate_copy(\n",
                "    num_examples: int = 10,\n",
                "    num_categories: int = 10,\n",
                "    copy_len: int = 10,\n",
                "    blank_len: int = 10,\n",
                "    selective: bool = False,\n",
                "    one_hot: bool = True,\n",
                "    seed: int = 1_337,\n",
                "    dtype: torch.dtype = torch.bfloat16,\n",
                ") -> TensorDataset:\n",
                "    \"\"\"\n",
                "    Generate a copy task dataset inspired by Arjovsky, Shah, and Bengio (2016).\n",
                "\n",
                "    Task Description:\n",
                "    - Input sequence: [copy_sequence][pre_delim_blanks][delimiter][post_delim_blanks]\n",
                "    - Output sequence: [blank_tokens][copy_sequence]\n",
                "\n",
                "    The task requires remembering a categorical sequence for a variable number of time steps.\n",
                "\n",
                "    Args:\n",
                "        num_examples: Number of examples to generate.\n",
                "        num_categories: Number of token categories.\n",
                "            - Categories 0 to num_categories-3: Tokens to be copied.\n",
                "            - Category num_categories-2: Blank token.\n",
                "            - Category num_categories-1: Delimiter token.\n",
                "        copy_len: Length of the sequence to be copied.\n",
                "        blank_len: Number of blank tokens after the delimiter in the input sequence.\n",
                "        selective: If True, inserts blank tokens between the tokens in the copied sequence (pre-delimiter).\n",
                "        seed: Random seed for reproducibility.\n",
                "\n",
                "    Returns:\n",
                "        TensorDataset with:\n",
                "            - inputs: Shape (num_examples, seq_len)\n",
                "              where seq_len is:\n",
                "              - copy_len + (num_categories-1) + blank_len + 1\n",
                "            - targets: Shape (num_examples, num_categories + blank_len + copy_len)\n",
                "              where the output consists of blank tokens followed by the copied sequence.\n",
                "\n",
                "    Example:\n",
                "        >>> dataset = generate_copy(num_examples=10, num_categories=10, copy_len=3, blank_len=10, selective=True)\n",
                "        >>> inputs, targets = dataset[0]\n",
                "        >>> print(inputs.shape, targets.shape)\n",
                "        torch.Size([23]) torch.Size([23])\n",
                "\n",
                "    Note:\n",
                "        A memoryless baseline strategy would predict the blank token for the first\n",
                "        (num_categories + blank_len) steps, then random tokens, yielding a categorical\n",
                "        cross entropy of (copy_len * log(num_categories-2)) / (num_categories + blank_len + copy_len).\n",
                "    \"\"\"\n",
                "    torch.manual_seed(seed)\n",
                "\n",
                "    # Assign characters\n",
                "    blank_char = num_categories - 2  # Reserve penultimate token for blank\n",
                "    delim_char = num_categories - 1  # Reserve last token for delimiter\n",
                "\n",
                "    # Construct input sequences\n",
                "    to_copy = torch.randint(\n",
                "        0, blank_char, # random sequence in [0, blank_char)\n",
                "        (num_examples, copy_len) # num_examples many random sequences\n",
                "    )\n",
                "    pre_delim_blanks = torch.full(\n",
                "        (num_examples, num_categories - 1), # num_examples many sequences of pre_delim blanks\n",
                "        blank_char\n",
                "    )\n",
                "    delim = torch.full(\n",
                "        (num_examples, 1),  # num_examples many delimiters\n",
                "        delim_char\n",
                "    )\n",
                "    post_delim_blanks = torch.full(\n",
                "        (num_examples, blank_len),  # \"Remaining 10 entries are set to a_8\"\n",
                "        blank_char\n",
                "    )\n",
                "\n",
                "    if selective:\n",
                "        # Selective case\n",
                "        def insert_pre_delim_blanks(row):\n",
                "            pre_delim_len = copy_len + num_categories - 1  # Length of the copied sequence + pre-delim blanks\n",
                "            insert_positions = torch.randperm(pre_delim_len)[:num_categories - 1]  # Randomly select positions for blanks\n",
                "            inserted_row = torch.full((pre_delim_len,), blank_char)  # Fill with blank_char\n",
                "            mask = torch.ones(pre_delim_len, dtype=torch.bool)  # Mask to identify which positions to replace with to_copy\n",
                "            mask[insert_positions] = False  # Positions for blanks\n",
                "            inserted_row[mask] = row  # Insert the copied sequence where the mask allows\n",
                "            return inserted_row\n",
                "\n",
                "        inputs = torch.stack([insert_pre_delim_blanks(row) for row in to_copy])\n",
                "    else:\n",
                "        # Non-selective case\n",
                "        inputs = torch.cat((to_copy, pre_delim_blanks), dim=1)\n",
                "\n",
                "    # Add delimiter and post-delimiter blanks\n",
                "    inputs = torch.cat((inputs, delim, post_delim_blanks), dim=1)\n",
                "\n",
                "    # Construct output sequences\n",
                "    blank_output = torch.full(\n",
                "        (num_examples, num_categories + blank_len),\n",
                "        blank_char\n",
                "    )\n",
                "    outputs = torch.cat((blank_output, to_copy), dim=1)\n",
                "\n",
                "    if one_hot:\n",
                "        inputs = F.one_hot(inputs, num_classes=num_categories).to(dtype)\n",
                "        outputs = F.one_hot(outputs, num_classes=num_categories).to(dtype)\n",
                "\n",
                "    return TensorDataset(inputs, outputs)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "from torch.utils.data import TensorDataset\n",
                "\n",
                "\n",
                "def generate_document_similarity(\n",
                "    num_examples: int = 10,\n",
                "    num_documents: int = 10,\n",
                "    num_elements: int = 10,\n",
                "    top_k: int = 2,\n",
                "    seed: int = 1_337,\n",
                "    dtype: torch.dtype = torch.bfloat16,\n",
                ") -> TensorDataset:\n",
                "    \"\"\"\n",
                "    Generate a dataset for the cosine similarity task. The goal is to find the\n",
                "    pair of documents (tensors) with the highest cosine similarity.\n",
                "    \n",
                "    Alman and Yu (2024) claimed that no sub-quadratic model can solve this task:\n",
                "    https://arxiv.org/abs/2410.04271.\n",
                "    \n",
                "    \n",
                "    Args:\n",
                "        num_examples (int): Number of examples (sets of documents) to generate.\n",
                "        num_documents (int): Number of documents (tensors) in each example.\n",
                "        num_elements (int): Number of elements in each document.\n",
                "        top_k (int): Number of top similar document pairs to identify.\n",
                "        seed (int): Random seed for reproducibility.\n",
                "        dtype (torch.dtype): Data type for the tensors.\n",
                "    \n",
                "    Returns:\n",
                "        TensorDataset:\n",
                "            - Inputs: Shape (num_examples, num_documents, num_elements)\n",
                "            - Targets: Shape (num_examples, top_k, 2) - the indices of the document pairs \n",
                "              with the highest cosine similarity.\n",
                "    \"\"\"\n",
                "    torch.manual_seed(seed)\n",
                "\n",
                "    # Validate parameters\n",
                "    if top_k < 1:\n",
                "        raise ValueError(\"top_k must be at least 1.\")\n",
                "    if num_documents < 2:\n",
                "        raise ValueError(\"num_documents must be at least 2 to form pairs.\")\n",
                "    max_topk = num_documents * (num_documents - 1) // 2\n",
                "    if top_k > max_topk:\n",
                "        raise ValueError(f\"top_k={top_k} exceeds the maximum number of unique document pairs ({max_topk}).\")\n",
                "    \n",
                "    # Generate and normalize the inputs\n",
                "    inputs = torch.randn((num_examples, num_documents, num_elements), dtype=dtype)\n",
                "    normalized_inputs = F.normalize(inputs, p=2, dim=2)\n",
                "    \n",
                "    # Compute the cosine similarity between all pairs of documents\n",
                "    cosine_similarity = normalized_inputs @ normalized_inputs.transpose(1, 2)\n",
                "    \n",
                "    # Get upper triangular indices (excluding diagonal)\n",
                "    triu_indices = torch.triu_indices(num_documents, num_documents, offset=1)\n",
                "    \n",
                "    # Extract upper triangular similarities\n",
                "    sim_pairs = cosine_similarity[:, triu_indices[0], triu_indices[1]]  # Shape: (num_examples, num_pairs)\n",
                "    \n",
                "    # Get top_k indices for each example\n",
                "    topk_values, topk_indices = torch.topk(sim_pairs, top_k, dim=1, largest=True, sorted=True)\n",
                "    \n",
                "    # Map topk_indices to pair indices\n",
                "    topk_pairs = triu_indices[:, topk_indices]  # Shape: (2, num_examples, top_k)\n",
                "    targets = topk_pairs.permute(1, 2, 0)  # Shape: (num_examples, top_k, 2)\n",
                "\n",
                "    return TensorDataset(inputs, targets)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_spectral_filters(\n",
                "    seq_len: int,\n",
                "    K: int,\n",
                "    use_hankel_L: bool = False,\n",
                "    device: torch.device = None,\n",
                "    dtype: torch.dtype = torch.bfloat16,\n",
                ") -> torch.Tensor:\n",
                "    Z = get_hankel(seq_len, use_hankel_L).to(device)\n",
                "    sigma, phi = torch.linalg.eigh(Z)\n",
                "    sigma_k, phi_k = sigma[-K:], phi[:, -K:]\n",
                "    phi_k *= sigma_k ** 0.25\n",
                "    phi_k = phi_k.to(device=device, dtype=dtype)\n",
                "    return phi_k\n",
                "\n",
                "def get_hankel(seq_len: int, use_hankel_L: bool = False) -> torch.Tensor:\n",
                "    entries = torch.arange(1, seq_len + 1, dtype=torch.float64)\n",
                "    i_plus_j = entries[:, None] + entries[None, :]\n",
                "\n",
                "    if use_hankel_L:\n",
                "        sgn = (-1.0) ** (i_plus_j - 2.0) + 1.0\n",
                "        denom = (i_plus_j + 3.0) * (i_plus_j - 1.0) * (i_plus_j + 1.0)\n",
                "        Z = sgn * (8.0 / denom)\n",
                "    elif not use_hankel_L:\n",
                "        Z = 2.0 / (i_plus_j**3 - i_plus_j)\n",
                "    else:\n",
                "        raise ValueError(\"use_hankel_L must be a boolean\")\n",
                "\n",
                "    return Z\n",
                "\n",
                "def compute_dimensions(n: int) -> tuple[int, int, int]:\n",
                "    if n <= 2:\n",
                "        raise ValueError(\"n must be greater than 2\")\n",
                "\n",
                "    T_prime = (math.ceil(math.sqrt(n - 2)))**2 + 2\n",
                "    sqrt_T_prime = math.ceil(math.sqrt(T_prime - 2))\n",
                "    k_max = sqrt_T_prime\n",
                "    return T_prime, sqrt_T_prime, k_max\n",
                "\n",
                "def get_tensorized_spectral_filters(\n",
                "    n: int = 8192,\n",
                "    k: int = 24,\n",
                "    use_hankel_L: bool = False,\n",
                "    device: torch.device = None,\n",
                "    dtype: torch.dtype = torch.bfloat16,\n",
                ") -> torch.Tensor:\n",
                "    \"\"\"\n",
                "    Compute tensorized spectral filters for given sequence length and filter count.\n",
                "\n",
                "    Args:\n",
                "        n: Sequence length\n",
                "        k: Number of filters\n",
                "        use_hankel_L: Hankel_main ⊗ Hankel_L? Default is Hankel_main ⊗ Hankel_main.\n",
                "        device: Computation device\n",
                "        dtype: Computation dtype\n",
                "    \"\"\"\n",
                "    T_prime, sqrt_T_prime, k_max = compute_dimensions(n)\n",
                "    k = min(k, k_max)\n",
                "\n",
                "    Z = get_hankel(sqrt_T_prime)\n",
                "    sigma, phi = torch.linalg.eigh(Z)\n",
                "    phi_i = phi[:, -k:] * sigma[-k:] ** 0.25\n",
                "\n",
                "    if use_hankel_L: # TODO: We may want to use Hankel_L above too if use_hankel_L is true, make another variable for this (mix != use_hankel_L)\n",
                "        Z_L = get_hankel(sqrt_T_prime, True)\n",
                "        sigma_L, phi_L = torch.linalg.eigh(Z_L)\n",
                "        phi_j = phi_L[:, -k:] * sigma_L[-k:] ** 0.25\n",
                "    else:\n",
                "        phi_j = phi_i\n",
                "\n",
                "    filters = torch.kron(phi_i, phi_j)\n",
                "    return filters.to(device=device, dtype=dtype)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "class Attention(nn.Module):\n",
                "    def __init__(self, n_embd, n_heads):\n",
                "        super().__init__()\n",
                "        assert n_embd % n_heads == 0, f\"n_embd ({n_embd}) must be divisible by n_heads ({n_heads})\"\n",
                "        self.n_heads = n_heads\n",
                "        self.head_dim = n_embd // n_heads\n",
                "        self.wq = nn.Linear(n_embd, n_embd)\n",
                "        self.wk = nn.Linear(n_embd, n_embd)\n",
                "        self.wv = nn.Linear(n_embd, n_embd)\n",
                "        self.o_proj = nn.Linear(n_embd, n_embd)\n",
                "\n",
                "    def forward(self, x):\n",
                "        bsz, seqlen, dim = x.shape\n",
                "        Q = self.wq(x).view(bsz, seqlen, self.n_heads, self.head_dim).transpose(1, 2)  # (B, N, S, D)\n",
                "        K = self.wk(x).view(bsz, seqlen, self.n_heads, self.head_dim).transpose(1, 2)  # (B, N, S, D)\n",
                "        V = self.wv(x).view(bsz, seqlen, self.n_heads, self.head_dim).transpose(1, 2)  # (B, N, S, D)\n",
                "\n",
                "        # causal mask\n",
                "        mask = torch.triu(torch.ones(seqlen, seqlen, device=x.device), diagonal=1).bool()  # (S, S)\n",
                "\n",
                "        # use scaled_dot_product_attention\n",
                "        attn_output = F.scaled_dot_product_attention(\n",
                "            Q, K, V,\n",
                "            attn_mask=mask,\n",
                "            dropout_p=0.0\n",
                "        )  # (B, N, S, D)\n",
                "\n",
                "        attn_output = attn_output.transpose(1, 2).contiguous().view(bsz, seqlen, dim)\n",
                "        return self.o_proj(attn_output)\n",
                "\n",
                "class MLP(nn.Module):\n",
                "    def __init__(self, dim):\n",
                "        super().__init__()\n",
                "        self.hidden_dim = 4 * dim\n",
                "        self.gate_proj = nn.Linear(dim, self.hidden_dim)\n",
                "        self.up_proj = nn.Linear(dim, self.hidden_dim)\n",
                "        self.down_proj = nn.Linear(self.hidden_dim, dim)\n",
                "        self.dropout = nn.Dropout(0.1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        gate = self.gate_proj(x)\n",
                "        modulated_gate = F.silu(gate)\n",
                "        up = self.up_proj(x)\n",
                "        fuse = modulated_gate * up\n",
                "        outputs = self.down_proj(fuse)\n",
                "        outputs = self.dropout(outputs)\n",
                "        return outputs\n",
                "\n",
                "class AttentionLayer(nn.Module):\n",
                "    def __init__(self, n_embd, n_heads):\n",
                "        super().__init__()\n",
                "        self.attn = Attention(n_embd, n_heads)\n",
                "        self.mlp = MLP(n_embd)\n",
                "        self.attn_norm = nn.LayerNorm(n_embd)\n",
                "        self.mlp_norm = nn.LayerNorm(n_embd)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = x + self.attn(self.attn_norm(x))\n",
                "        x = x + self.mlp(self.mlp_norm(x))\n",
                "        return x\n",
                "\n",
                "class Transformer(nn.Module):\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.num_layers = config.num_layers\n",
                "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
                "        self.dropout = nn.Dropout(config.dropout)\n",
                "        self.layers = nn.ModuleList([AttentionLayer(config.n_embd, config.n_heads) for _ in range(config.num_layers)])\n",
                "        self.norm = nn.LayerNorm(config.n_embd)\n",
                "        self.output = nn.Linear(config.n_embd, config.vocab_size)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.dropout(self.tok_emb(x))\n",
                "        for layer in self.layers:\n",
                "            x = layer(x)\n",
                "        x = self.norm(x)\n",
                "        return self.output(x)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import math\n",
                "\n",
                "class LearnableSpectralFilters(nn.Module):\n",
                "    def __init__(self, seq_len, k, use_hankel_L=False, device=None, dtype=torch.float32):\n",
                "        super().__init__()\n",
                "        self.seq_len = seq_len\n",
                "        self.k = k\n",
                "        self.use_hankel_L = use_hankel_L\n",
                "        self.device = device\n",
                "\n",
                "        filters = get_tensorized_spectral_filters(\n",
                "            n=seq_len,\n",
                "            k=k,\n",
                "            use_hankel_L=use_hankel_L,\n",
                "            device=device,\n",
                "            dtype=dtype,\n",
                "        )\n",
                "        self.filters = nn.Parameter(filters).to(device)\n",
                "\n",
                "    def forward(self):\n",
                "        return self.filters\n",
                "\n",
                "class SpectralAttention(nn.Module):\n",
                "    \"\"\"\n",
                "    Implements the linear form of structured masked attention using spectral filters.\n",
                "    According to the linear form:\n",
                "\n",
                "    Z = contract(V,K) -> (B,S,i,j) with i,j=k\n",
                "    H = contract(L,Z) -> (B,T,i,j)\n",
                "    Y = contract(Q,H) -> (B,T,j)\n",
                "\n",
                "    Then project Y back to (B,T,dim).\n",
                "\n",
                "    We print shapes at each step for verification.\n",
                "    \"\"\"\n",
                "    def __init__(self, seq_len, n_embd, k, use_hankel_L=False, device=None):\n",
                "        super().__init__()\n",
                "        self.seq_len = seq_len\n",
                "        self.k = k\n",
                "\n",
                "        self.Q_filt = LearnableSpectralFilters(seq_len, k, use_hankel_L, device).filters.transpose(0, 1)\n",
                "        self.K_filt = LearnableSpectralFilters(seq_len, k, use_hankel_L, device).filters.transpose(0, 1)\n",
                "        self.V_filt = LearnableSpectralFilters(seq_len, k, use_hankel_L, device).filters.transpose(0, 1)\n",
                "\n",
                "        # i_proj maps input embedding to the filter dimension\n",
                "        self.i_proj = nn.Linear(n_embd, self.Q_filt.shape[0])\n",
                "        # o_proj maps back from filter dimension to embedding dimension\n",
                "        self.o_proj = nn.Linear(self.Q_filt.shape[0], n_embd)\n",
                "\n",
                "    def forward(self, x, L):\n",
                "        # x: (B,T,dim)\n",
                "        # L: (B,T,S) lower-triangular mask, typically T=S\n",
                "        bsz, T, dim = x.shape\n",
                "        S = self.seq_len\n",
                "\n",
                "        # Project input to filter dimension space\n",
                "        x_proj = self.i_proj(x) # (B,T,h)\n",
                "        \n",
                "        # Compute Q, K, V = (B,T,k)\n",
                "        Q = torch.einsum(\"bth,hk->btk\", x_proj, self.Q_filt)\n",
                "        K = torch.einsum(\"bth,hk->btk\", x_proj, self.K_filt)\n",
                "        V = torch.einsum(\"bth,hk->btk\", x_proj, self.V_filt)\n",
                "\n",
                "        # print(\"Q shape:\", Q.shape)  # (B,T,k)\n",
                "        # print(\"K shape:\", K.shape)  # (B,T,k)\n",
                "        # print(\"V shape:\", V.shape)  # (B,T,k)\n",
                "        # print(\"L shape:\", L.shape)  # (B,T,S)\n",
                "\n",
                "        # Step 1: Z = (b,s,i,j)\n",
                "        # Here s = T = S, i and j both = k\n",
                "        Z = torch.einsum(\"bsi, bsj -> bsij\", V, K)\n",
                "        # print(\"Z shape:\", Z.shape)  # (B,T,k,k)\n",
                "\n",
                "        # Step 2: H = (b,t,i,j) by contracting L (B,T,S) with Z (B,S,i,j)\n",
                "        H = torch.einsum(\"bts, bsij-> btij\", L, Z)\n",
                "        # print(\"H shape:\", H.shape)  # (B,T,k,k)\n",
                "\n",
                "        # Step 3: Y = (b,t,j) by contracting Q (b,t,i) with H (b,t,i,j)\n",
                "        Y = torch.einsum(\"bti, btij -> btj\", Q, H)\n",
                "        # print(\"Y shape before projection:\", Y.shape)  # (B,T,k)\n",
                "\n",
                "        # Project back to (B,T,dim)\n",
                "        Y = self.o_proj(Y)\n",
                "        # print(\"Y shape after projection:\", Y.shape)\n",
                "        return Y\n",
                "\n",
                "class SpectralAttentionLayer(nn.Module):\n",
                "    def __init__(self, seq_len, n_embd, k, dropout=0.1, use_hankel_L=False, device=None):\n",
                "        super().__init__()\n",
                "        print('here', device)\n",
                "        self.attn_norm = nn.LayerNorm(n_embd)\n",
                "        self.mlp_norm = nn.LayerNorm(n_embd)\n",
                "        self.attn = SpectralAttention(seq_len, n_embd, k, use_hankel_L, device)\n",
                "        self.mlp = MLP(n_embd)\n",
                "\n",
                "    def forward(self, x, L):\n",
                "        x = x + self.attn(self.attn_norm(x), L)\n",
                "        x = x + self.mlp(self.mlp_norm(x))\n",
                "        return x\n",
                "\n",
                "class SpectralTransformer(nn.Module):\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.num_layers = config.num_layers\n",
                "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
                "        self.dropout = nn.Dropout(config.dropout)\n",
                "        self.layers = nn.ModuleList([\n",
                "            SpectralAttentionLayer(config.seq_len, config.n_embd, config.k, config.dropout, device=config.device)\n",
                "            for _ in range(config.num_layers)\n",
                "        ])\n",
                "        self.norm = nn.LayerNorm(config.n_embd)\n",
                "        self.output = nn.Linear(config.n_embd, config.vocab_size)\n",
                "\n",
                "    def forward(self, x):\n",
                "        bsz, seq_len = x.size()\n",
                "\n",
                "        # Construct lower-triangular mask L: (B,T,S)\n",
                "        L = torch.tril(torch.ones(seq_len, seq_len, device=x.device))\n",
                "        L = L.unsqueeze(0).expand(bsz, -1, -1)  # (B,T,S)\n",
                "\n",
                "        x = self.dropout(self.tok_emb(x))  # (B,T,embed)\n",
                "        for layer in self.layers:\n",
                "            x = layer(x, L)\n",
                "        x = self.norm(x)\n",
                "        return self.output(x)\n",
                "\n",
                "class Config:\n",
                "    def __init__(self, vocab_size, seq_len, n_embd, num_layers, k, dropout, device):\n",
                "        self.vocab_size = vocab_size\n",
                "        self.seq_len = seq_len\n",
                "        self.n_embd = n_embd\n",
                "        self.num_layers = num_layers\n",
                "        self.k = k\n",
                "        self.dropout = dropout\n",
                "        self.device = device\n",
                "\n",
                "# Example usage:\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "config = Config(vocab_size=12, seq_len=128, n_embd=32, num_layers=2, k=24, dropout=0.0, device=device)\n",
                "model = SpectralTransformer(config).to(device)\n",
                "input_ids = torch.randint(0, config.vocab_size, (4, config.seq_len)).to(device)\n",
                "output = model(input_ids)\n",
                "print(output.shape)  # (4,64,12)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -----------------------------\n",
                "# Required Imports\n",
                "# -----------------------------\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
                "import math\n",
                "import time\n",
                "from tqdm import tqdm\n",
                "import random\n",
                "import numpy as np\n",
                "\n",
                "# -----------------------------\n",
                "# Utility Functions\n",
                "# -----------------------------\n",
                "\n",
                "def format_num(num: int) -> str:\n",
                "    if num >= 1_000_000_000:\n",
                "        return f\"{num / 1_000_000_000:.2f}B\"\n",
                "    elif num >= 1_000_000:\n",
                "        return f\"{num / 1_000_000:.2f}M\"\n",
                "    elif num >= 1000:\n",
                "        return f\"{num / 1000:.2f}K\"\n",
                "    else:\n",
                "        return str(num)\n",
                "\n",
                "def count_non_embedding_params(model):\n",
                "    total_params = 0\n",
                "    non_embedding_params = 0\n",
                "    for name, param in model.named_parameters():\n",
                "        if param.requires_grad:\n",
                "            num_params = param.numel()\n",
                "            total_params += num_params\n",
                "            if 'emb' not in name:\n",
                "                non_embedding_params += num_params\n",
                "\n",
                "    print(f\"Total parameters: {format_num(total_params)}\")\n",
                "    print(f\"Parameters (excluding embeddings): {format_num(non_embedding_params)}\")\n",
                "\n",
                "def set_seed(seed: int = 1746):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "# Set the seed for reproducibility\n",
                "set_seed(1746)\n",
                "\n",
                "# -----------------------------\n",
                "# Configuration\n",
                "# -----------------------------\n",
                "\n",
                "class Config:\n",
                "    def __init__(self):\n",
                "        # Dataset parameters\n",
                "        self.num_examples = 30000\n",
                "        self.num_categories = 12\n",
                "        self.copy_len = 10\n",
                "        self.blank_len = 10\n",
                "        self.selective = False\n",
                "\n",
                "        # Model parameters\n",
                "        self.num_layers = 2\n",
                "        self.n_heads = 8\n",
                "        self.n_embd = 512\n",
                "        self.vocab_size = self.num_categories\n",
                "        self.seq_len = self.copy_len + (self.num_categories - 1) + 1 + self.blank_len\n",
                "        self.k = 24\n",
                "        self.use_hankel_L = False\n",
                "\n",
                "        # Training parameters\n",
                "        self.batch_size = 1\n",
                "        self.lr = 1e-2\n",
                "        self.num_epochs = 1\n",
                "\n",
                "        # Others: set device\n",
                "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "        self.dropout = 0.0\n",
                "\n",
                "config = Config()\n",
                "\n",
                "print(f\"Using device: {config.device}\")\n",
                "\n",
                "# -----------------------------\n",
                "# Dataset Preparation\n",
                "# -----------------------------\n",
                "\n",
                "dataset = generate_copy(\n",
                "    num_examples=config.num_examples,\n",
                "    num_categories=config.num_categories,\n",
                "    copy_len=config.copy_len,\n",
                "    blank_len=config.blank_len,\n",
                "    selective=config.selective,\n",
                "    one_hot=False,\n",
                "    seed=1746,\n",
                "    dtype=torch.long,\n",
                ")\n",
                "\n",
                "train_size = int(0.8 * len(dataset))\n",
                "test_size = len(dataset) - train_size\n",
                "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
                "\n",
                "# Use pinned memory if on GPU for faster host-to-device transfers\n",
                "pin_memory = True if config.device.type == 'cuda' else False\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, pin_memory=pin_memory)\n",
                "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, pin_memory=pin_memory)\n",
                "\n",
                "# -----------------------------\n",
                "# Model Initialization\n",
                "# -----------------------------\n",
                "\n",
                "transformer = Transformer(config).to(config.device)\n",
                "spectral_transformer = SpectralTransformer(config).to(config.device)\n",
                "count_non_embedding_params(transformer)\n",
                "count_non_embedding_params(spectral_transformer)\n",
                "\n",
                "# -----------------------------\n",
                "# Loss and Optimizer\n",
                "# -----------------------------\n",
                "\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer_transformer = torch.optim.AdamW(transformer.parameters(), lr=config.lr)\n",
                "optimizer_spectral = torch.optim.AdamW(spectral_transformer.parameters(), lr=config.lr)\n",
                "\n",
                "# Optional: gradient clipping to improve stability\n",
                "grad_clip = None\n",
                "\n",
                "# -----------------------------\n",
                "# Training and Evaluation Loops\n",
                "# -----------------------------\n",
                "\n",
                "def train(model, optimizer, loader, device, desc=\"Training\"):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    progress_bar = tqdm(loader, desc=desc, leave=False)\n",
                "    for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
                "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs)\n",
                "        # Reshape for loss\n",
                "        outputs = outputs.view(-1, config.vocab_size)\n",
                "        targets = targets.view(-1)\n",
                "\n",
                "        loss = criterion(outputs, targets)\n",
                "        loss.backward()\n",
                "\n",
                "        if grad_clip is not None:\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
                "\n",
                "        optimizer.step()\n",
                "\n",
                "        total_loss += loss.item()\n",
                "        progress_bar.set_postfix({'Loss': loss.item(), 'LR': optimizer.param_groups[0]['lr']})\n",
                "\n",
                "    avg_loss = total_loss / len(loader)\n",
                "    return avg_loss\n",
                "\n",
                "@torch.no_grad()\n",
                "def evaluate(model, loader, device, desc=\"Evaluating\"):\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    progress_bar = tqdm(loader, desc=desc, leave=False)\n",
                "    for inputs, targets in progress_bar:\n",
                "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
                "\n",
                "        outputs = model(inputs)\n",
                "        outputs = outputs.view(-1, config.vocab_size)\n",
                "        targets = targets.view(-1)\n",
                "\n",
                "        loss = criterion(outputs, targets)\n",
                "        total_loss += loss.item()\n",
                "\n",
                "        _, predicted = torch.max(outputs, dim=1)\n",
                "        correct += (predicted == targets).sum().item()\n",
                "        total += targets.size(0)\n",
                "\n",
                "    avg_loss = total_loss / len(loader)\n",
                "    accuracy = correct / total\n",
                "    return avg_loss, accuracy\n",
                "\n",
                "# -----------------------------\n",
                "# Training Execution\n",
                "# -----------------------------\n",
                "\n",
                "best_test_acc_t = 0.0\n",
                "best_test_acc_s = 0.0\n",
                "\n",
                "for epoch in range(1, config.num_epochs + 1):\n",
                "    epoch_start_time = time.time()\n",
                "\n",
                "    print(f\"\\nEpoch {epoch}/{config.num_epochs}\")\n",
                "    print(\"-\" * 30)\n",
                "    loss_train_t = train(transformer, optimizer_transformer, train_loader, config.device, desc=\"Training Transformer\")\n",
                "    loss_test_t, acc_test_t = evaluate(transformer, test_loader, config.device, desc=\"Evaluating Transformer\")\n",
                "\n",
                "    loss_train_s = train(spectral_transformer, optimizer_spectral, train_loader, config.device, desc=\"Training SpectralTransformer\")\n",
                "    loss_test_s, acc_test_s = evaluate(spectral_transformer, test_loader, config.device, desc=\"Evaluating SpectralTransformer\")\n",
                "\n",
                "    epoch_elapsed = time.time() - epoch_start_time\n",
                "\n",
                "    # Track best accuracy\n",
                "    if acc_test_t > best_test_acc_t:\n",
                "        best_test_acc_t = acc_test_t\n",
                "    if acc_test_s > best_test_acc_s:\n",
                "        best_test_acc_s = acc_test_s\n",
                "\n",
                "    print(f\"Epoch {epoch} completed in {epoch_elapsed:.2f}s\")\n",
                "    print(f\"  Transformer    | Train Loss: {loss_train_t:.4f} | Test Loss: {loss_test_t:.4f} | Test Acc: {acc_test_t:.4f} (Best: {best_test_acc_t:.4f})\")\n",
                "    print(f\"  SpectralTransf | Train Loss: {loss_train_s:.4f} | Test Loss: {loss_test_s:.4f} | Test Acc: {acc_test_s:.4f} (Best: {best_test_acc_s:.4f})\")\n",
                "\n",
                "print(\"\\nFinal Evaluation on Test Set:\")\n",
                "loss_test_t, acc_test_t = evaluate(transformer, test_loader, config.device, desc=\"Final Evaluation Transformer\")\n",
                "loss_test_s, acc_test_s = evaluate(spectral_transformer, test_loader, config.device, desc=\"Final Evaluation SpectralTransformer\")\n",
                "\n",
                "print(f\"Transformer    | Test Loss: {loss_test_t:.4f} | Test Accuracy: {acc_test_t:.4f}\")\n",
                "print(f\"SpectralTransf | Test Loss: {loss_test_s:.4f} | Test Accuracy: {acc_test_s:.4f}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "thesis",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}